"""
è½¯ä»¶ç•Œé¢_codeéƒ¨åˆ†
å¯ä»¥å•ç‹¬å¯¼å…¥å›¾ç‰‡ã€æ’­æ”¾è§†é¢‘ã€ä½¿ç”¨æ‘„åƒå¤´
å¯¼å…¥æ¨¡å‹çš„æ—¶å€™ä¼šä½¿ç”¨yolo_analyzeræ¨¡å—æ¥åˆ†ææ˜¯ä»€ä¹ˆæ¨¡å‹
æŒ‰ä¸‹å¼€å§‹æ—¶å€™æ‰æ­£å¼æ£€æµ‹
"""

import os
import sys
import importlib
import traceback
import threading
import time
from pathlib import Path
from typing import Dict, Any, Optional, Tuple
import numpy as np

from PySide6.QtCore import QObject, QThread, Signal, QTimer, Qt, QMutex, QWaitCondition
from PySide6.QtGui import QPixmap, QImage, QPainter
from PySide6.QtWidgets import (
    QMessageBox, QFileDialog, QApplication, QDialog, QVBoxLayout, 
    QPushButton, QLabel, QScrollArea, QWidget
)

# å¯¼å…¥UI
from window_ui import YOLOMainWindowUI


class SimpleVideoPlayer(QObject):
    """æç®€è§†é¢‘æ’­æ”¾å™¨ - åªè´Ÿè´£æµç•…æ˜¾ç¤ºï¼Œä¸æ¶‰åŠYOLO"""
    
    frame_ready = Signal(QImage)  # å¸§å°±ç»ªä¿¡å·ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
    status_update = Signal(str)   # çŠ¶æ€æ›´æ–°
    progress_updated = Signal(int, int, float)  # æ–°å¢ï¼šè¿›åº¦æ›´æ–°ä¿¡å· (å½“å‰å¸§, æ€»å¸§æ•°, å½“å‰æ—¶é—´)
    finished = Signal()           # æ’­æ”¾å®Œæˆ
    
    def __init__(self):
        super().__init__()
        self.playing = False
        self.cap = None
        self.current_frame = None  # å½“å‰å¸§ï¼ˆnumpy arrayï¼‰
        self.frame_mutex = threading.Lock()
        self.play_thread = None
        
        # æ–°å¢è§†é¢‘ä¿¡æ¯
        self.total_frames = 0
        self.current_frame_num = 0
        self.fps = 30.0
        self.duration = 0.0

        # æ–°å¢ï¼šç”¨äº pause/resume çš„äº‹ä»¶ï¼ˆpause æ—¶ clear -> é˜»å¡ï¼›resume æ—¶ set -> ç»§ç»­ï¼‰
        self._pause_event = threading.Event()
        self._pause_event.set()   # é»˜è®¤ä¸é˜»å¡
        self.paused = False

        # ä¼˜åŒ–å¼€å…³ï¼šä½¿ç”¨ grab()/retrieve() æ¨¡å¼è¯»å–å¯å‡å°‘éƒ¨åˆ†è§£ç é˜»å¡
        self._use_grab = True
    
    def play_video(self, video_path: str):
        """æ’­æ”¾è§†é¢‘æ–‡ä»¶ - æç®€ç‰ˆæœ¬"""
        if self.play_thread and self.play_thread.is_alive():
            self.stop()
        
        self.playing = True
        self.paused = False
        self._pause_event.set()
        self.play_thread = threading.Thread(
            target=self._video_playback_simple,
            args=(video_path,),
            daemon=True
        )
        self.play_thread.start()
    
    def play_camera(self, camera_id: int = 0):
        """æ’­æ”¾æ‘„åƒå¤´ - æç®€ç‰ˆæœ¬"""
        if self.play_thread and self.play_thread.is_alive():
            self.stop()
        
        self.playing = True
        self.paused = False
        self._pause_event.set()
        self.play_thread = threading.Thread(
            target=self._camera_playback_simple,
            args=(camera_id,),
            daemon=True
        )
        self.play_thread.start()
    
    def stop(self):
        """åœæ­¢æ’­æ”¾"""
        # æ ‡è®°åœæ­¢å¹¶é‡Šæ”¾ç­‰å¾…ï¼Œç¡®ä¿çº¿ç¨‹èƒ½é€€å‡º
        self.playing = False
        self._pause_event.set()
        if self.cap:
            try:
                self.cap.release()
            except:
                pass
            self.cap = None
        
        if self.play_thread and self.play_thread.is_alive():
            self.play_thread.join(timeout=1.0)
        
        self.finished.emit()
    
    def pause(self):
        """æš‚åœæ’­æ”¾ï¼ˆä¸ä¼šç»“æŸçº¿ç¨‹ï¼‰"""
        # åªé˜»å¡è¯»å–çº¿ç¨‹ï¼Œä¸é‡Šæ”¾èµ„æº
        self.paused = True
        self._pause_event.clear()
    
    def resume(self):
        """ç»§ç»­æ’­æ”¾ï¼ˆå”¤é†’è¯»å–çº¿ç¨‹ï¼‰"""
        # å¦‚æœçº¿ç¨‹å·²ç»ç»“æŸï¼Œéœ€è¦é‡æ–°å¯åŠ¨ï¼ˆå°è¯•é‡å¯ç”¨äºedgeæƒ…å½¢ï¼‰
        if not (self.play_thread and self.play_thread.is_alive()) and self.cap is None and self.current_frame is None:
            # çº¿ç¨‹å·²ä¸å­˜åœ¨ä¸”æ²¡æœ‰æ‰“å¼€èµ„æºï¼Œæ— æ³•è‡ªåŠ¨æ¢å¤
            # ä¸Šå±‚åº”åœ¨éœ€è¦æ—¶é‡æ–°è°ƒç”¨ play_video/play_camera
            self.paused = False
            self._pause_event.set()
            return
        
        self.paused = False
        self._pause_event.set()
    
    def get_current_frame(self):
        """è·å–å½“å‰å¸§ï¼ˆç”¨äºæŠ“å–ï¼‰"""
        with self.frame_mutex:
            # è¿”å›æ‹·è´ï¼Œé¿å…å…±äº«åº•å±‚ç¼“å†²å¼•èµ·å¹¶å‘é—®é¢˜
            return self.current_frame.copy() if (self.current_frame is not None and hasattr(self.current_frame, 'copy')) else None

    def seek_frame(self, target_frame: int):
        """è·³è½¬åˆ°æŒ‡å®šå¸§å¹¶ç«‹å³è¯»å–ä¸€å¸§ç”¨äºæ›´æ–°æ˜¾ç¤ºï¼ˆä¾›è¿›åº¦æ¡æ‹–åŠ¨ä½¿ç”¨ï¼‰"""
        try:
            import cv2
            if not self.cap or not self.cap.isOpened():
                return
            # è®¾ç½®ç›®æ ‡å¸§å·å¹¶è¯»å–ä¸€å¸§
            self.cap.set(cv2.CAP_PROP_POS_FRAMES, max(0, int(target_frame)))
            # ä½¿ç”¨ grab/retrieve å°è¯•æ›´å¿«è¯»å–
            if self._use_grab:
                self.cap.grab()
                ret, frame = self.cap.retrieve()
            else:
                ret, frame = self.cap.read()
            if not ret:
                return
            # æ‹·è´å¸§
            with self.frame_mutex:
                self.current_frame = frame.copy()
                try:
                    self.current_frame_num = int(self.cap.get(cv2.CAP_PROP_POS_FRAMES))
                except:
                    pass
            # å‘å‡ºè¿›åº¦ä¸å¸§ä¿¡å·
            current_time = self.current_frame_num / max(1.0, self.fps)
            self.progress_updated.emit(self.current_frame_num, self.total_frames, current_time)
            # è½¬æ¢ä¸ºQImageå¹¶å‘é€ï¼ˆæ˜¾ç¤ºç”¨ï¼‰
            frame_rgb = cv2.cvtColor(self.current_frame, cv2.COLOR_BGR2RGB)
            # ç¡®ä¿è¿ç»­å†…å­˜ï¼Œé¿å…QImageè¯»å…±äº«å†…å­˜å‡ºç°é—®é¢˜
            frame_rgb = np.ascontiguousarray(frame_rgb)
            height, width, channel = frame_rgb.shape
            bytes_per_line = 3 * width
            q_img = QImage(frame_rgb.data, width, height, bytes_per_line, QImage.Format_RGB888).copy()
            self.frame_ready.emit(q_img)
        except Exception:
            # ä¿æŒç¨³å®šï¼Œä¸æ‰“å°é¢å¤–æ—¥å¿—
            traceback.print_exc()

    def _video_playback_simple(self, video_path: str):
        """ç®€å•çš„è§†é¢‘æ’­æ”¾ - ä¸“æ³¨äºæµç•…æ˜¾ç¤º"""
        try:
            import cv2
            import numpy as np

            self.cap = cv2.VideoCapture(video_path)
            if not self.cap.isOpened():
                self.status_update.emit(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
                return

            # å°è¯•è®¾ç½®è¾ƒå°çš„å†…éƒ¨ç¼“å†²ï¼ˆéƒ¨åˆ† OpenCV åç«¯æ”¯æŒï¼‰
            try:
                self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 2)
            except:
                pass

            # è·å–è§†é¢‘ä¿¡æ¯
            self.total_frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))
            self.fps = self.cap.get(cv2.CAP_PROP_FPS)
            if self.fps <= 0:
                self.fps = 30.0

            if self.total_frames > 0:
                self.duration = self.total_frames / self.fps
            else:
                # å¦‚æœæ— æ³•è·å–æ€»å¸§æ•°ï¼Œè®¾ç½®ä¸º1000ä½œä¸ºé»˜è®¤èŒƒå›´
                self.total_frames = 1000

            self.status_update.emit(f"å¼€å§‹æ’­æ”¾è§†é¢‘: {os.path.basename(video_path)}")
            self.status_update.emit(f"æ€»å¸§æ•°: {self.total_frames}, FPS: {self.fps:.2f}")

            frame_interval = 1.0 / self.fps if self.fps > 0 else 0.033

            # ä¿è¯å¸§å·æœ‰åˆå§‹å€¼
            try:
                self.current_frame_num = int(self.cap.get(cv2.CAP_PROP_POS_FRAMES))
            except:
                self.current_frame_num = 0

            # å¦‚æœä½¿ç”¨ grab æ¨¡å¼ï¼Œå…ˆåšå°‘é‡é¢„æŠ“å–ä»¥å‡è½»é¦–å¸§å»¶è¿Ÿ
            if self._use_grab:
                for _ in range(2):
                    try:
                        self.cap.grab()
                    except:
                        break

            while self.playing:
                # å¦‚æœè¢«æš‚åœï¼Œé˜»å¡ç›´åˆ° resumeï¼ˆæˆ– stopï¼‰
                if not self._pause_event.is_set():
                    self._pause_event.wait()
                    if not self.playing:
                        break

                loop_start = time.time()

                # è¯»å–ä¸€å¸§ï¼šä¼˜å…ˆå°è¯• grab/retrieveï¼ˆéƒ¨åˆ†åç«¯æ›´å¿«ï¼‰
                if self._use_grab:
                    ok = self.cap.grab()
                    if not ok:
                        # åˆ°å°¾æˆ–è€…è¯»å–å¤±è´¥ï¼Œå°è¯•å›åˆ°0æˆ–é€€å‡º
                        try:
                            self.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                            self.current_frame_num = 0
                            continue
                        except:
                            break
                    ret, frame = self.cap.retrieve()
                else:
                    ret, frame = self.cap.read()

                if not ret or frame is None:
                    # è§†é¢‘åˆ°å°¾éƒ¨ï¼Œå°è¯•å¾ªç¯
                    try:
                        self.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                        self.current_frame_num = 0
                        continue
                    except:
                        break

                # æ‹·è´å¹¶ä¿å­˜å½“å‰å¸§ï¼ˆç”¨äºæŠ“å–ï¼‰
                with self.frame_mutex:
                    self.current_frame = frame.copy()

                # æ›´æ–°å½“å‰å¸§å·ï¼ˆå°½é‡ä» cap æŸ¥è¯¢ï¼‰
                try:
                    pos = int(self.cap.get(cv2.CAP_PROP_POS_FRAMES))
                    if pos >= 0:
                        self.current_frame_num = pos
                    else:
                        self.current_frame_num += 1
                except:
                    self.current_frame_num += 1

                # å‘é€è¿›åº¦ä¿¡æ¯
                current_time = self.current_frame_num / self.fps if self.fps > 0 else 0.0
                self.progress_updated.emit(self.current_frame_num, self.total_frames, current_time)

                # è½¬æ¢ä¸ºQImageå¹¶å‘é€ï¼ˆæ˜¾ç¤ºç”¨ï¼‰
                try:
                    frame_rgb = cv2.cvtColor(self.current_frame, cv2.COLOR_BGR2RGB)
                    frame_rgb = np.ascontiguousarray(frame_rgb)
                    height, width, channel = frame_rgb.shape
                    bytes_per_line = 3 * width

                    # åˆ›å»ºQImageï¼ˆåŸºäºè¿ç»­å†…å­˜ï¼‰ï¼Œå¹¶æ‹·è´ç¡®ä¿æ•°æ®ç‹¬ç«‹
                    q_img = QImage(frame_rgb.data, width, height, bytes_per_line, QImage.Format_RGB888).copy()
                    self.frame_ready.emit(q_img)
                except Exception:
                    traceback.print_exc()

                # æ›´å‡†ç¡®çš„ç­‰å¾…ï¼šè€ƒè™‘æœ¬æ¬¡è§£ç è€—æ—¶ï¼Œä½¿ç”¨ Event.wait æ¥æ”¯æŒ pause/å³æ—¶æ¢å¤
                elapsed = time.time() - loop_start
                wait_time = max(0.0, frame_interval - elapsed)
                # å¦‚æœæš‚åœï¼Œä¼šåœ¨ä¸‹æ¬¡å¾ªç¯å¼€å§‹æ—¶é˜»å¡
                self._pause_event.wait(timeout=wait_time)

            if self.cap:
                try:
                    self.cap.release()
                except:
                    pass
                self.cap = None

        except Exception:
            self.status_update.emit(f"è§†é¢‘æ’­æ”¾é”™è¯¯")
            traceback.print_exc()
        finally:
            self.playing = False
            self._pause_event.set()
            self.finished.emit()
    
    def _camera_playback_simple(self, camera_id: int):
        """ç®€å•çš„æ‘„åƒå¤´æ’­æ”¾ - ä¸“æ³¨äºæµç•…æ˜¾ç¤º"""
        try:
            import cv2
            import numpy as np

            self.cap = cv2.VideoCapture(camera_id)
            if not self.cap.isOpened():
                self.status_update.emit(f"æ— æ³•æ‰“å¼€æ‘„åƒå¤´: {camera_id}")
                return

            # è®¾ç½®æ‘„åƒå¤´å‚æ•°
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            # å°è¯•è®¾ç½®è¾ƒå°ç¼“å†²
            try:
                self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
            except:
                pass

            # æ‘„åƒå¤´å¯åŠ¨æ—¶åšå°‘é‡é¢„çƒ­è¯»å–ï¼Œå‡å°‘é¦–å¸§å¡é¡¿
            for _ in range(3):
                try:
                    ret_warm, _ = self.cap.read()
                except:
                    ret_warm = False
                if not ret_warm:
                    break
                time.sleep(0.01)

            self.status_update.emit(f"å¼€å§‹æ‘„åƒå¤´å®æ—¶æ˜¾ç¤º")

            while self.playing:
                # ç­‰å¾…resumeï¼ˆå¦‚æœå¤„äºæš‚åœçŠ¶æ€ä¼šé˜»å¡åœ¨è¿™é‡Œï¼‰
                if not self._pause_event.is_set():
                    self._pause_event.wait()
                    if not self.playing:
                        break

                loop_start = time.time()

                # è¯»å–ä¸€å¸§
                ret, frame = self.cap.read()
                if not ret or frame is None:
                    self.status_update.emit("æ— æ³•è¯»å–æ‘„åƒå¤´ç”»é¢")
                    time.sleep(0.02)
                    continue

                # ä¿å­˜å½“å‰å¸§ï¼ˆç”¨äºæŠ“å–ï¼‰ï¼Œåšæ‹·è´
                with self.frame_mutex:
                    self.current_frame = frame.copy()

                # è½¬æ¢ä¸ºQImageå¹¶å‘é€ï¼ˆæ˜¾ç¤ºç”¨ï¼‰
                try:
                    frame_rgb = cv2.cvtColor(self.current_frame, cv2.COLOR_BGR2RGB)
                    frame_rgb = np.ascontiguousarray(frame_rgb)
                    height, width, channel = frame_rgb.shape
                    bytes_per_line = 3 * width

                    q_img = QImage(frame_rgb.data, width, height, bytes_per_line, QImage.Format_RGB888).copy()
                    self.frame_ready.emit(q_img)
                except Exception:
                    traceback.print_exc()

                # æ§åˆ¶å¸§ç‡ï¼ˆçº¦30fpsï¼‰ï¼Œä½¿ç”¨ wait æ”¯æŒ pause å“åº”
                elapsed = time.time() - loop_start
                wait_time = max(0.0, 0.033 - elapsed)
                self._pause_event.wait(timeout=wait_time)

            if self.cap:
                try:
                    self.cap.release()
                except:
                    pass
                self.cap = None

        except Exception:
            self.status_update.emit(f"æ‘„åƒå¤´æ’­æ”¾é”™è¯¯")
            traceback.print_exc()
        finally:
            self.playing = False
            self._pause_event.set()
            self.finished.emit()


class FrameGrabberWorker(QObject):
    """å¸§æŠ“å–å·¥ä½œè€… - è´Ÿè´£ä»æ’­æ”¾å™¨æŠ“å–å¸§å¹¶å‘é€ç»™YOLO"""
    
    frame_processed = Signal(QImage)  # æ–°å¢ï¼šå¤„ç†åçš„å¸§ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
    frame_grabbed = Signal(object)    # æŠ“å–çš„å¸§ï¼ˆnumpy arrayï¼‰
    processing_complete = Signal(dict)  # å¤„ç†å®Œæˆï¼ˆç»Ÿè®¡ä¿¡æ¯ï¼‰
    status_update = Signal(str)
    finished = Signal()
    error_occurred = Signal(str)
    
    def __init__(self, video_player: SimpleVideoPlayer, yolo_module=None):
        super().__init__()
        self.video_player = video_player
        self.yolo_module = yolo_module
        self.processing = False
        self.grab_interval = 5  # æ¯5å¸§æŠ“å–ä¸€æ¬¡
        self.frame_count = 0
        self.grab_thread = None
        
        # å¤„ç†ç»Ÿè®¡
        self.total_frames_processed = 0
        self.total_detections = 0
        self.total_inference_time = 0.0
        self.start_time = 0
        
        # æ€§èƒ½è·Ÿè¸ª
        self.last_frame_time = 0
    
    def start_grabbing(self, grab_interval: int = 5):
        """å¼€å§‹æŠ“å–å¸§"""
        if self.grab_thread and self.grab_thread.is_alive():
            self.stop_grabbing()
        
        self.grab_interval = grab_interval
        self.processing = True
        self.frame_count = 0
        self.total_frames_processed = 0
        self.total_detections = 0
        self.total_inference_time = 0.0
        self.start_time = time.time()
        self.last_frame_time = time.time()
        
        self.grab_thread = threading.Thread(
            target=self._grab_frames,
            daemon=True
        )
        self.grab_thread.start()
    
    def stop_grabbing(self):
        """åœæ­¢æŠ“å–"""
        self.processing = False
        if self.grab_thread and self.grab_thread.is_alive():
            self.grab_thread.join(timeout=1.0)
        self.finished.emit()
    
    def set_yolo_module(self, yolo_module):
        """è®¾ç½®YOLOæ¨¡å—"""
        self.yolo_module = yolo_module
    
    def _grab_frames(self):
        """æŠ“å–å¸§çš„æ ¸å¿ƒé€»è¾‘"""
        self.status_update.emit("å¼€å§‹æŠ“å–å¸§è¿›è¡Œæ£€æµ‹...")
        
        try:
            import cv2
            import numpy as np
            
            while self.processing:
                # ä»æ’­æ”¾å™¨è·å–å½“å‰å¸§
                frame = self.video_player.get_current_frame()
                
                if frame is None:
                    time.sleep(0.1)  # ç­‰å¾…å¸§å°±ç»ª
                    continue
                
                self.frame_count += 1
                
                # æŒ‰é—´éš”æŠ“å–ï¼ˆé¿å…æ¯å¸§éƒ½å¤„ç†ï¼‰
                if self.frame_count % self.grab_interval == 0:
                    try:
                        current_time = time.time()
                        frame_interval = current_time - self.last_frame_time
                        self.last_frame_time = current_time
                        
                        # å¦‚æœæœ‰YOLOæ¨¡å—ï¼Œè¿›è¡Œå¤„ç†
                        if self.yolo_module and hasattr(self.yolo_module, 'process_frame'):
                            # è®°å½•æ¨ç†å¼€å§‹æ—¶é—´
                            inference_start = time.time()
                            
                            # è°ƒç”¨YOLOæ¨¡å—å¤„ç†å¸§ï¼ˆè¿”å›å­—å…¸ï¼‰
                            result_dict = self.yolo_module.process_frame(frame)
                            
                            # è®°å½•æ¨ç†æ—¶é—´
                            inference_time = time.time() - inference_start
                            self.total_inference_time += inference_time
                            self.total_frames_processed += 1
                            
                            # ä»å­—å…¸ä¸­æå–å›¾åƒå’Œç»“æœ
                            processed_frame = result_dict.get('image', frame)
                            results_data = result_dict.get('stats', {})
                            
                            # æå–ç»Ÿè®¡ä¿¡æ¯
                            stats = self._extract_statistics(results_data)
                            stats['inference_time'] = inference_time * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
                            stats['fps'] = 1.0 / frame_interval if frame_interval > 0 else 0
                            
                            # æ›´æ–°ç´¯è®¡æ£€æµ‹æ•°
                            detection_count = stats.get('detection_count', 0)
                            if 'detection_count' in stats:
                                self.total_detections += detection_count
                                stats['total_detections'] = self.total_detections
                            
                            # å‘é€å¤„ç†åçš„å¸§ç”¨äºæ˜¾ç¤º
                            if isinstance(processed_frame, np.ndarray):
                                # å°†OpenCVå›¾åƒè½¬æ¢ä¸ºQImage
                                if len(processed_frame.shape) == 2:  # ç°åº¦å›¾
                                    processed_rgb = cv2.cvtColor(processed_frame, cv2.COLOR_GRAY2RGB)
                                elif processed_frame.shape[2] == 4:  # RGBA
                                    processed_rgb = cv2.cvtColor(processed_frame, cv2.COLOR_BGRA2RGB)
                                else:  # BGR
                                    processed_rgb = cv2.cvtColor(processed_frame, cv2.COLOR_BGR2RGB)
                                
                                height, width, channel = processed_rgb.shape
                                bytes_per_line = 3 * width
                                
                                q_img = QImage(processed_rgb.data, width, height, 
                                              bytes_per_line, QImage.Format_RGB888)
                                self.frame_processed.emit(q_img)
                            
                            # å‘é€ç»Ÿè®¡ä¿¡æ¯
                            stats['total_processed'] = self.total_frames_processed
                            stats['avg_inference_time'] = (self.total_inference_time / 
                                                         self.total_frames_processed * 1000 
                                                         if self.total_frames_processed > 0 else 0)
                            
                            # å¦‚æœæœ‰åˆ†ç±»ä¿¡æ¯ï¼Œæ·»åŠ åˆ°ç»Ÿè®¡ä¸­
                            if 'class_name' in result_dict and result_dict['class_name'] != 'æœªçŸ¥':
                                stats['class_name'] = result_dict['class_name']
                                stats['confidence'] = result_dict.get('confidence', 0.0)
                            
                            self.processing_complete.emit(stats)
                        
                    except Exception as e:
                        self.error_occurred.emit(f"å¸§å¤„ç†é”™è¯¯: {str(e)}")
                        traceback.print_exc()
                
                # æ§åˆ¶æŠ“å–é¢‘ç‡ï¼ˆä¸è¦å¤ªå¿«ï¼‰
                time.sleep(0.05)  # æ¯ç§’æœ€å¤š20æ¬¡æŠ“å–
        
        except Exception as e:
            self.error_occurred.emit(f"æŠ“å–è¿‡ç¨‹é”™è¯¯: {str(e)}")
            traceback.print_exc()
        finally:
            self.processing = False
            self.finished.emit()
    
    def _extract_statistics(self, results) -> Dict[str, Any]:
        """ä»YOLOç»“æœä¸­æå–ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'detection_count': 0,
            'inference_time': 0,
            'fps': 0.0,
            'avg_confidence': 0.0,
            'classes': {},
            'tracked_objects': 0
        }
        
        if results is None:
            return stats
        
        # å¦‚æœæ˜¯å­—å…¸æ ¼å¼çš„ç»“æœ
        if isinstance(results, dict):
            stats.update({k: results.get(k, v) for k, v in stats.items()})
            
            # å¦‚æœæœ‰å…·ä½“å­—æ®µï¼Œä½¿ç”¨å®ƒä»¬
            if 'detection_count' in results:
                stats['detection_count'] = results['detection_count']
            if 'avg_confidence' in results:
                stats['avg_confidence'] = results['avg_confidence']
            if 'class_name' in results:
                stats['classes'] = {results['class_name']: 1}
        
        return stats


class YOLOMainWindowLogic(QObject):
    """ä¸»çª—å£é€»è¾‘æ§åˆ¶å™¨ - ç®€åŒ–ç‰ˆæœ¬"""
    
    def __init__(self, ui_window: YOLOMainWindowUI):
        super().__init__()
        self.ui = ui_window
        
        # æ ¸å¿ƒç»„ä»¶
        self.video_player = SimpleVideoPlayer()      # æç®€æ’­æ”¾å™¨
        self.frame_grabber = FrameGrabberWorker(self.video_player)  # å¸§æŠ“å–å™¨
        
        # çŠ¶æ€å˜é‡
        self.current_yolo_module = None
        self.model_loaded = False
        self.model_path = None
        self.selected_module_type = None
        
        # å¤„ç†çŠ¶æ€
        self.is_processing = False      # æ˜¯å¦æ­£åœ¨YOLOå¤„ç†
        self.is_playing = False         # æ˜¯å¦æ­£åœ¨æ’­æ”¾
        self.current_file = None
        self.current_mode = None        # 'image', 'video', 'camera'
        
        # é»˜è®¤å‚æ•°
        self.default_params = {
            'iou_threshold': 0.45,
            'confidence_threshold': 0.5,
            'delay_ms': 10,
            'line_width': 2
        }
        
        # å…ˆåˆå§‹åŒ–UIçŠ¶æ€ï¼Œå†è®¾ç½®è¿æ¥
        self._init_ui_state()
        self._setup_connections()
        
        print("YOLOé€»è¾‘æ§åˆ¶å™¨åˆå§‹åŒ–å®Œæˆ - ç®€åŒ–ç‰ˆæœ¬")
    
    def _init_ui_state(self):
        """åˆå§‹åŒ–UIçŠ¶æ€"""
        # è·å–UIç»„ä»¶å¼•ç”¨
        self.left_panel = self.ui.get_left_panel()
        self.right_panel = self.ui.get_right_panel()
        
        # è®¾ç½®é»˜è®¤å‚æ•°
        self.right_panel.set_parameters(**self.default_params)
        
        # æ˜¾ç¤ºåˆå§‹çŠ¶æ€
        self.left_panel.clear_display()
        self.right_panel.update_model_info()
        
        # è®¾ç½®æ§åˆ¶æŒ‰é’®çŠ¶æ€
        self.right_panel.set_control_state(False)
    
    def _setup_connections(self):
        """è®¾ç½®ä¿¡å·è¿æ¥"""
        # ===== è¿æ¥è§†é¢‘æ’­æ”¾å™¨ä¿¡å· =====
        self.video_player.frame_ready.connect(self._on_player_frame)
        self.video_player.status_update.connect(self._on_status_update)
        self.video_player.progress_updated.connect(self._on_progress_updated)  # æ–°å¢è¿›åº¦ä¿¡å·
        self.video_player.finished.connect(self._on_player_finished)
        
        # ===== è¿æ¥å¸§æŠ“å–å™¨ä¿¡å· =====
        self.frame_grabber.frame_processed.connect(self._on_frame_processed)  # æ–°å¢ï¼šå¤„ç†åçš„å¸§
        self.frame_grabber.frame_grabbed.connect(self._on_frame_grabbed)
        self.frame_grabber.processing_complete.connect(self._on_processing_complete)
        self.frame_grabber.status_update.connect(self._on_status_update)
        self.frame_grabber.error_occurred.connect(self._on_grabber_error)
        self.frame_grabber.finished.connect(self._on_grabber_finished)
        
        # ===== æ–‡ä»¶èœå•ä¿¡å· =====
        self.ui.file_menu_init.connect(self._on_file_init)
        self.ui.file_menu_exit.connect(self._on_file_exit)
        
        # ===== å¸®åŠ©èœå•ä¿¡å· =====
        self.ui.help_menu_about.connect(self._on_help_about)
        self.ui.help_menu_manual.connect(self._on_help_manual)
        
        # ===== ä¸»è¦åŠŸèƒ½ä¿¡å· =====
        self.ui.model_load.connect(self._on_model_load)
        self.ui.image_open.connect(self._on_image_open)
        self.ui.video_open.connect(self._on_video_open)
        self.ui.camera_open.connect(self._on_camera_open)
        
        # ===== æ§åˆ¶æŒ‰é’®ä¿¡å· =====
        self.right_panel.start_inference.connect(self._on_start_inference)
        self.right_panel.stop_inference.connect(self._on_stop_inference)
        self.right_panel.save_screenshot.connect(self._on_save_screenshot)
        
        # ===== å·¦ä¾§é¢æ¿æ’­æ”¾/æš‚åœä¿¡å· =====
        self.ui.left_panel_play_pause.connect(self._on_play_pause_clicked)
        
        # ===== å·¦ä¾§é¢æ¿è¿›åº¦æ¡ä¿¡å· =====
        self.left_panel.progress_changed.connect(self._on_progress_changed)
    
    # ============================================================================
    # ä¿¡å·å¤„ç†æ–¹æ³•
    # ============================================================================
    
    def _on_player_frame(self, q_image: QImage):
        """æ¥æ”¶åˆ°æ’­æ”¾å™¨çš„åŸå§‹å¸§ - ç›´æ¥æ˜¾ç¤ºï¼ˆæ— YOLOå¤„ç†æ—¶ï¼‰"""
        try:
            if not self.is_processing:
                pixmap = QPixmap.fromImage(q_image)
                self.left_panel.set_display_image(pixmap)
        except Exception as e:
            print(f"æ˜¾ç¤ºåŸå§‹å¸§å¤±è´¥: {e}")
    
    def _on_frame_processed(self, q_image: QImage):
        """æ¥æ”¶åˆ°å¤„ç†åçš„å¸§ - æ˜¾ç¤ºYOLOæ£€æµ‹ç»“æœ"""
        try:
            pixmap = QPixmap.fromImage(q_image)
            self.left_panel.set_display_image(pixmap)
        except Exception as e:
            print(f"æ˜¾ç¤ºå¤„ç†å¸§å¤±è´¥: {e}")
    
    def _on_player_finished(self):
        """æ’­æ”¾å™¨å®Œæˆ"""
        self.is_playing = False
        self.left_panel.set_play_state(False)
        print("æ’­æ”¾å™¨åœæ­¢")
    
    def _on_frame_grabbed(self, frame):
        """æ¥æ”¶åˆ°æŠ“å–çš„å¸§ - å¯ä»¥åœ¨è¿™é‡Œå¤„ç†æˆ–å‘é€ç»™å…¶ä»–æ¨¡å—"""
        # è¿™é‡Œå¯ä»¥ä¿å­˜å¸§ã€è®°å½•æ—¥å¿—ç­‰
        pass
    
    def _on_processing_complete(self, stats: dict):
        """å¤„ç†å®Œæˆ - æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        try:
            # æ›´æ–°åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
            self.right_panel.update_statistics(
                detection_count=stats.get('detection_count', 0),
                confidence=stats.get('avg_confidence', 0.0),
                inference_time=stats.get('inference_time', 0),
                fps=stats.get('fps', 0.0)
            )
            
            # å¦‚æœæœ‰ç±»åˆ†å¸ƒä¿¡æ¯ï¼Œæ›´æ–°è¯¦ç»†ç»Ÿè®¡
            if 'classes' in stats and stats['classes']:
                class_distribution = "\n".join([f"{cls}: {count}" for cls, count in stats['classes'].items()])
                self.right_panel.update_detailed_stats(
                    total_processed=stats.get('total_processed', 0),
                    total_detections=stats.get('total_detections', 0),
                    avg_inference_time=stats.get('avg_inference_time', 0),
                    class_distribution=class_distribution
                )
            
        except Exception as e:
            print(f"æ›´æ–°ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
    
    def _on_grabber_error(self, error_msg: str):
        """æŠ“å–å™¨é”™è¯¯"""
        print(f"æŠ“å–å™¨é”™è¯¯: {error_msg}")
    
    def _on_grabber_finished(self):
        """æŠ“å–å™¨å®Œæˆ"""
        self.is_processing = False
        self.right_panel.set_control_state(False)
        print("å¸§æŠ“å–åœæ­¢")
    
    def _on_status_update(self, status: str):
        """çŠ¶æ€æ›´æ–°"""
        print(f"çŠ¶æ€: {status}")
    
    def _on_progress_updated(self, current_frame, total_frames, current_time):
        """è§†é¢‘è¿›åº¦æ›´æ–°"""
        try:
            if self.current_mode == 'video':
                # æ›´æ–°è¿›åº¦æ¡èŒƒå›´ï¼ˆä½¿ç”¨0-1000èŒƒå›´ï¼Œæ–¹ä¾¿UIæ˜¾ç¤ºï¼‰
                self.left_panel.set_progress_range(0, 1000)
                
                # è®¡ç®—è¿›åº¦å€¼ï¼ˆ0-1000ï¼‰
                if total_frames > 0:
                    progress_value = int((current_frame / total_frames) * 1000)
                    self.left_panel.set_progress_value(progress_value)
                
                # æ›´æ–°æ—¶é—´æ˜¾ç¤º
                current_time_str = self._format_time(current_time)
                total_time_str = self._format_time(total_frames / self.video_player.fps) if self.video_player.fps > 0 else "--:--"
                self.left_panel.set_time_display(current_time_str, total_time_str)
                
        except Exception as e:
            print(f"æ›´æ–°è¿›åº¦å¤±è´¥: {e}")
    
    def _on_progress_changed(self, value):
        """ç”¨æˆ·æ‹–åŠ¨è¿›åº¦æ¡"""
        if self.current_mode == 'video' and hasattr(self.video_player, 'cap') and self.video_player.cap:
            try:
                import cv2
                # è·³è½¬åˆ°æŒ‡å®šä½ç½®
                total_frames = self.video_player.total_frames
                if total_frames > 0:
                    # valueæ˜¯0-1000ï¼Œè½¬æ¢ä¸ºå¸§å·
                    target_frame = int((value / 1000.0) * total_frames)
                    # ä¿®æ”¹ä¸ºä½¿ç”¨æ’­æ”¾å™¨çš„seek_frameæ–¹æ³•
                    self.video_player.seek_frame(target_frame)
                    
                    print(f"è·³è½¬åˆ°è¿›åº¦: {value}/1000, å¸§å·: {target_frame}/{total_frames}")
            except Exception as e:
                print(f"è·³è½¬è¿›åº¦å¤±è´¥: {e}")
    
    def _on_play_pause_clicked(self):
        """æ’­æ”¾/æš‚åœæŒ‰é’®ç‚¹å‡»"""
        try:
            if self.current_mode == 'video':
                if self.video_player.playing:
                    self.video_player.pause()
                    self.left_panel.set_play_state(False)
                else:
                    self.video_player.resume()
                    self.left_panel.set_play_state(True)
            elif self.current_mode == 'camera':
                if self.video_player.playing:
                    self.video_player.pause()
                    self.left_panel.set_play_state(False)
                else:
                    self.video_player.resume()
                    self.left_panel.set_play_state(True)
        except Exception as e:
            print(f"æ’­æ”¾/æš‚åœå¤±è´¥: {e}")
    
    # ============================================================================
    # æ–‡ä»¶èœå•å¤„ç†æ–¹æ³•
    # ============================================================================
    
    def _on_file_init(self):
        """åˆå§‹åŒ–"""
        reply = QMessageBox.question(
            self.ui, "ç¡®è®¤åˆå§‹åŒ–",
            "æ˜¯å¦è¦åˆå§‹åŒ–æ‰€æœ‰è®¾ç½®ï¼Ÿ",
            QMessageBox.Yes | QMessageBox.No,
            QMessageBox.No
        )
        
        if reply == QMessageBox.Yes:
            self._stop_all()
            self._init_ui_state()
            QMessageBox.information(self.ui, "åˆå§‹åŒ–å®Œæˆ", "æ‰€æœ‰è®¾ç½®å·²é‡ç½®")
    
    def _on_file_exit(self):
        """é€€å‡º"""
        reply = QMessageBox.question(
            self.ui, "ç¡®è®¤é€€å‡º",
            "æ˜¯å¦è¦é€€å‡ºYOLOæ£€æµ‹ç³»ç»Ÿï¼Ÿ",
            QMessageBox.Yes | QMessageBox.No,
            QMessageBox.No
        )
        
        if reply == QMessageBox.Yes:
            self._stop_all()
            self.ui.close()
    
    # ============================================================================
    # å¸®åŠ©èœå•å¤„ç†æ–¹æ³•
    # ============================================================================
    
    def _on_help_about(self):
        """æ˜¾ç¤ºå…³äºå¯¹è¯æ¡†"""
        about_text = f"""
        <h3>YOLOå¤šåŠŸèƒ½æ£€æµ‹ç³»ç»Ÿ</h3>
        
        <b>ç‰ˆæœ¬:</b> 1.0.0<br>
        <b>ä½œè€…:</b> Sephoration<br><br>
        
        <b>åŠŸèƒ½ç‰¹ç‚¹:</b><br>
        â€¢ ç›®æ ‡æ£€æµ‹ä¸è·Ÿè¸ª<br>
        â€¢ å…³é”®ç‚¹/å§¿æ€æ£€æµ‹<br>
        â€¢ å›¾åƒåˆ†ç±»<br>
        â€¢ æ”¯æŒå›¾ç‰‡ã€è§†é¢‘ã€æ‘„åƒå¤´<br>
        â€¢ å®æ—¶ç»Ÿè®¡ä¸å¯è§†åŒ–<br><br>
        
        <b>æŠ€æœ¯æ”¯æŒ:</b><br>
        â€¢ PySide6 (Qt for Python)<br>
        â€¢ Ultralytics YOLO<br>
        â€¢ OpenCV<br><br>
        
        <b>Â© 2024 ç‰ˆæƒæ‰€æœ‰</b>
        """
        
        QMessageBox.about(self.ui, "å…³äº", about_text)
    
    def _on_help_manual(self):
        """æ˜¾ç¤ºä½¿ç”¨è¯´æ˜"""
        manual_text = """
        <h3>YOLOå¤šåŠŸèƒ½æ£€æµ‹ç³»ç»Ÿ - ä½¿ç”¨è¯´æ˜</h3>
        
        <b>1. åŠ è½½æ¨¡å‹</b><br>
        â€¢ ç‚¹å‡»"æ‰“å¼€æ¨¡å‹"æŒ‰é’®é€‰æ‹©YOLOæ¨¡å‹æ–‡ä»¶ (.pt)<br>
        â€¢ é€‰æ‹©å¯¹åº”çš„æ¨¡å—ç±»å‹ï¼šåˆ†æå™¨(ç›®æ ‡æ£€æµ‹)ã€åˆ†ç±»å™¨ã€å…³é”®ç‚¹æ£€æµ‹<br><br>
        
        <b>2. æ‰“å¼€åª’ä½“æ–‡ä»¶</b><br>
        â€¢ <b>å›¾ç‰‡</b>: ç‚¹å‡»"æ‰“å¼€å›¾ç‰‡"ï¼Œé€‰æ‹©å›¾ç‰‡æ–‡ä»¶<br>
        â€¢ <b>è§†é¢‘</b>: ç‚¹å‡»"æ‰“å¼€è§†é¢‘"ï¼Œé€‰æ‹©è§†é¢‘æ–‡ä»¶<br>
        â€¢ <b>æ‘„åƒå¤´</b>: ç‚¹å‡»"æ‰“å¼€æ‘„åƒå¤´"ï¼Œä½¿ç”¨é»˜è®¤æ‘„åƒå¤´<br><br>
        
        <b>3. å‚æ•°è®¾ç½®</b><br>
        â€¢ <b>IOUé˜ˆå€¼</b>: æ§åˆ¶æ£€æµ‹æ¡†é‡å åº¦ (0.0-1.0)<br>
        â€¢ <b>ç½®ä¿¡åº¦</b>: è¿‡æ»¤ä½ç½®ä¿¡åº¦æ£€æµ‹ç»“æœ (0.0-1.0)<br>
        â€¢ <b>å»¶è¿Ÿ(ms)</b>: æ§åˆ¶å¤„ç†é—´éš”ï¼Œå½±å“å®æ—¶æ€§<br>
        â€¢ <b>çº¿å®½</b>: è°ƒæ•´æ£€æµ‹æ¡†å’Œå…³é”®ç‚¹çš„ç»˜åˆ¶çº¿å®½<br><br>
        
        <b>4. å¼€å§‹æ£€æµ‹</b><br>
        â€¢ ç‚¹å‡»"å¼€å§‹"æŒ‰é’®å¼€å§‹æ¨ç†å¤„ç†<br>
        â€¢ å®æ—¶ç»Ÿè®¡é¢æ¿æ˜¾ç¤ºå¤„ç†ç»“æœ<br>
        â€¢ ç‚¹å‡»"åœæ­¢"æŒ‰é’®ç»“æŸå¤„ç†<br><br>
        
        <b>5. è§†é¢‘æ§åˆ¶</b><br>
        â€¢ <b>æ’­æ”¾/æš‚åœ</b>: æ§åˆ¶è§†é¢‘æ’­æ”¾<br>
        â€¢ <b>è¿›åº¦æ¡</b>: æ‹–åŠ¨è·³è½¬åˆ°æŒ‡å®šä½ç½®<br>
        â€¢ <b>æ—¶é—´æ˜¾ç¤º</b>: æ˜¾ç¤ºå½“å‰/æ€»æ—¶é•¿<br><br>
        
        <b>6. å…¶ä»–åŠŸèƒ½</b><br>
        â€¢ <b>ä¿å­˜æˆªå›¾</b>: ä¿å­˜å½“å‰æ˜¾ç¤ºç”»é¢<br>
        â€¢ <b>åˆå§‹åŒ–</b>: é‡ç½®æ‰€æœ‰è®¾ç½®<br>
        â€¢ <b>é€€å‡º</b>: å…³é—­åº”ç”¨ç¨‹åº<br><br>
        
        <b>æç¤º:</b><br>
        â€¢ ç¡®ä¿å·²å®‰è£…å¿…è¦çš„Pythonåº“<br>
        â€¢ ä½¿ç”¨åˆé€‚çš„YOLOæ¨¡å‹æ–‡ä»¶<br>
        â€¢ è°ƒæ•´å‚æ•°ä»¥è·å¾—æœ€ä½³æ£€æµ‹æ•ˆæœ
        """
        
        QMessageBox.information(self.ui, "ä½¿ç”¨è¯´æ˜", manual_text)
    
    # ============================================================================
    # ä¸»è¦åŠŸèƒ½å¤„ç†æ–¹æ³•
    # ============================================================================
    
    def _on_model_load(self):
        """åŠ è½½æ¨¡å‹"""
        try:
            model_filter = "æ¨¡å‹æ–‡ä»¶ (*.pt *.pth *.onnx);;æ‰€æœ‰æ–‡ä»¶ (*.*)"
            model_path, _ = QFileDialog.getOpenFileName(
                self.ui, "é€‰æ‹©YOLOæ¨¡å‹æ–‡ä»¶",
                "", model_filter
            )
            
            if model_path:
                # æ¸…ç©ºä¹‹å‰çš„æ¨¡å‹ä¿¡æ¯
                self.model_path = None
                self.selected_module_type = None
                self.current_yolo_module = None
                self.model_loaded = False
                
                print(f"å¼€å§‹åˆ†ææ¨¡å‹: {model_path}")
                
                try:
                    # ä½¿ç”¨YOLOAnalyzeråˆ†ææ¨¡å‹ï¼ˆä¸åŠ è½½å®Œæ•´æ¨¡å‹ï¼‰
                    from yolo_analyzer import YOLOAnalyzer
                    
                    # åˆ†ææ¨¡å‹ä¿¡æ¯
                    model_info = YOLOAnalyzer.analyze_model(model_path)
                    
                    # è·å–ä»»åŠ¡ç±»å‹
                    task_type = model_info.get('task_type', 'detection')
                    
                    # ä»»åŠ¡ç±»å‹åˆ°æ¨¡å—ç±»å‹çš„æ˜ å°„
                    task_module_map = {
                        'detection': 'analyzer',
                        'classification': 'classifier',
                        'keypoint': 'keypoint',
                        'tracker': 'Tracker',
                        'segmentation': 'analyzer'  # åˆ†å‰²ä¹Ÿä½¿ç”¨åˆ†æå™¨
                    }
                    
                    if task_type not in task_module_map:
                        # æ˜¾ç¤ºé€‰æ‹©å¯¹è¯æ¡†
                        self._show_model_type_dialog(model_path)
                    else:
                        # è‡ªåŠ¨ç¡®å®šæ¨¡å—ç±»å‹
                        self.selected_module_type = task_module_map[task_type]
                        self.model_path = model_path
                        
                        # è·å–æ˜¾ç¤ºä¿¡æ¯
                        display_info = YOLOAnalyzer.get_model_info_for_display(model_info)
                        
                        # æ›´æ–°UIæ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯ï¼ˆä½†ä¸åŠ è½½æ¨¡å‹ï¼‰
                        self.right_panel.update_model_info(
                            model_path=model_path,
                            task_type=display_info['task_type'],
                            input_size=display_info['input_size'],
                            class_count=display_info['class_count']
                        )
                        
                        # æ˜¾ç¤ºæˆåŠŸä¿¡æ¯
                        QMessageBox.information(
                            self.ui, "æ¨¡å‹åˆ†ææˆåŠŸ",
                            f"âœ… å·²è‡ªåŠ¨è¯†åˆ«æ¨¡å‹ç±»å‹\n\n"
                            f"ğŸ“¦ æ¨¡å‹åç§°: {display_info['model_name']}\n"
                            f"ğŸ¯ ä»»åŠ¡ç±»å‹: {display_info['task_type']}\n"
                            f"ğŸ“ è¾“å…¥å°ºå¯¸: {display_info['input_size']}\n"
                            f"ğŸ”¢ ç±»åˆ«æ•°é‡: {display_info['class_count']}\n"
                            f"ğŸ’¾ æ–‡ä»¶å¤§å°: {display_info['file_size']}\n\n"
                            f"æ¨¡å‹å°†åœ¨ç‚¹å‡»'å¼€å§‹'æ—¶æ­£å¼åŠ è½½ã€‚"
                        )
                        
                        print(f"æ¨¡å‹åˆ†æå®Œæˆï¼Œç±»å‹: {self.selected_module_type}")
                    
                except Exception as e:
                    print(f"æ¨¡å‹åˆ†æå¤±è´¥: {e}")
                    # åˆ†æå¤±è´¥ï¼Œæ˜¾ç¤ºé€‰æ‹©å¯¹è¯æ¡†
                    self._show_model_type_dialog(model_path)
                    
        except Exception as e:
            self._show_error("é€‰æ‹©æ¨¡å‹å¤±è´¥", str(e))
    
    def _show_model_type_dialog(self, model_path):
        """æ˜¾ç¤ºæ¨¡å‹ç±»å‹é€‰æ‹©å¯¹è¯æ¡†ï¼ˆå½“è‡ªåŠ¨è¯†åˆ«å¤±è´¥æ—¶ï¼‰"""
        try:
            dialog = QDialog(self.ui)
            dialog.setWindowTitle("é€‰æ‹©æ¨¡å‹ç±»å‹")
            dialog.setFixedSize(300, 220)
            
            layout = QVBoxLayout(dialog)
            layout.setContentsMargins(20, 20, 20, 20)
            layout.setSpacing(15)
            
            model_name = os.path.basename(model_path)
            info_label = QLabel(f"å·²é€‰æ‹©æ¨¡å‹:\n{model_name}")
            info_label.setAlignment(Qt.AlignCenter)
            layout.addWidget(info_label)
            
            tip_label = QLabel("è¯·é€‰æ‹©å¤„ç†æ¨¡å—:")
            tip_label.setAlignment(Qt.AlignCenter)
            layout.addWidget(tip_label)
            
            btn_analyzer = QPushButton("åˆ†æå™¨ (ç›®æ ‡æ£€æµ‹)")
            btn_classifier = QPushButton("åˆ†ç±»å™¨ (å›¾åƒåˆ†ç±»)")
            btn_keypoint = QPushButton("å…³é”®ç‚¹æ£€æµ‹ (å§¿æ€)")
            btn_tracker = QPushButton("ç›®æ ‡è·Ÿè¸ª")
            
            button_style = """
                QPushButton {
                    background-color: #f0f0f0;
                    border: 1px solid #cccccc;
                    border-radius: 4px;
                    padding: 10px;
                    font-weight: normal;
                    min-height: 40px;
                }
                QPushButton:hover {
                    background-color: #e0e0e0;
                    border-color: #aaaaaa;
                }
            """
            
            for btn in [btn_analyzer, btn_classifier, btn_keypoint, btn_tracker]:
                btn.setStyleSheet(button_style)
            
            btn_analyzer.clicked.connect(lambda: self._select_module_type('analyzer', model_path, dialog))
            btn_classifier.clicked.connect(lambda: self._select_module_type('classifier', model_path, dialog))
            btn_keypoint.clicked.connect(lambda: self._select_module_type('keypoint', model_path, dialog))
            btn_tracker.clicked.connect(lambda: self._select_module_type('Tracker', model_path, dialog))
            
            layout.addWidget(btn_analyzer)
            layout.addWidget(btn_classifier)
            layout.addWidget(btn_keypoint)
            layout.addWidget(btn_tracker)
            
            dialog.exec()
            
        except Exception as e:
            self._show_error("é€‰æ‹©æ¨¡å‹ç±»å‹å¤±è´¥", str(e))
    
    def _select_module_type(self, module_type: str, model_path: str, dialog):
        """é€‰æ‹©æ¨¡å—ç±»å‹"""
        try:
            self.selected_module_type = module_type
            self.model_path = model_path
            
            module_display_names = {
                'analyzer': 'ç›®æ ‡æ£€æµ‹',
                'classifier': 'å›¾åƒåˆ†ç±»',
                'keypoint': 'å…³é”®ç‚¹æ£€æµ‹',
                'Tracker': 'ç›®æ ‡è·Ÿè¸ª'
            }
            
            display_name = module_display_names.get(module_type, module_type)
            
            # æ›´æ–°UIæ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯ï¼ˆä½†ä¸åŠ è½½æ¨¡å‹ï¼‰
            self.right_panel.update_model_info(
                model_path=model_path,
                task_type=display_name,
                input_size="640x640",  # é»˜è®¤å°ºå¯¸
                class_count="å¾…æ£€æµ‹"
            )
            
            # æ˜¾ç¤ºæˆåŠŸä¿¡æ¯
            QMessageBox.information(
                self.ui, "æ¨¡å‹é€‰æ‹©æˆåŠŸ",
                f"âœ… å·²é€‰æ‹©{display_name}æ¨¡å—\n\n"
                f"ğŸ“¦ æ¨¡å‹: {os.path.basename(model_path)}\n"
                f"ğŸ¯ ä»»åŠ¡: {display_name}\n\n"
                f"æ¨¡å‹å°†åœ¨ç‚¹å‡»'å¼€å§‹'æ—¶æ­£å¼åŠ è½½ã€‚"
            )
            
            print(f"å·²é€‰æ‹©{display_name}æ¨¡å—ï¼Œæ¨¡å‹å°†åœ¨ç‚¹å‡»'å¼€å§‹'æ—¶åŠ è½½")
            
            dialog.close()
            
        except Exception as e:
            self._show_error("é€‰æ‹©æ¨¡å—å¤±è´¥", str(e))
    
    def _on_image_open(self):
        """æ‰“å¼€å›¾ç‰‡"""
        try:
            self._stop_all()
            
            image_filter = "å›¾ç‰‡æ–‡ä»¶ (*.png *.jpg *.jpeg *.bmp *.gif);;æ‰€æœ‰æ–‡ä»¶ (*.*)"
            image_path, _ = QFileDialog.getOpenFileName(
                self.ui, "é€‰æ‹©å›¾ç‰‡æ–‡ä»¶",
                "", image_filter
            )
            
            if image_path:
                self.current_file = image_path
                self.current_mode = 'image'
                
                self.left_panel.update_info(os.path.basename(image_path), 'image')
                
                pixmap = QPixmap(image_path)
                if not pixmap.isNull():
                    self.left_panel.set_display_image(pixmap)
                    print(f"å·²åŠ è½½å›¾ç‰‡: {os.path.basename(image_path)}")
                else:
                    QMessageBox.warning(self.ui, "è­¦å‘Š", "æ— æ³•åŠ è½½å›¾ç‰‡æ–‡ä»¶")
                
        except Exception as e:
            self._show_error("æ‰“å¼€å›¾ç‰‡å¤±è´¥", str(e))
    
    def _on_video_open(self):
        """æ‰“å¼€è§†é¢‘"""
        try:
            self._stop_all()

            video_filter = "è§†é¢‘æ–‡ä»¶ (*.mp4 *.avi *.mov *.mkv *.flv);;æ‰€æœ‰æ–‡ä»¶ (*.*)"
            video_path, _ = QFileDialog.getOpenFileName(
                self.ui, "é€‰æ‹©è§†é¢‘æ–‡ä»¶",
                "", video_filter
            )

            if video_path:
                self.current_file = video_path
                self.current_mode = 'video'
                self.is_playing = True

                self.left_panel.update_info(os.path.basename(video_path), 'video')

                # å¯åŠ¨æç®€æ’­æ”¾å™¨
                self.video_player.play_video(video_path)

            print(f"å¼€å§‹æ’­æ”¾è§†é¢‘: {os.path.basename(video_path)}")
                
        except Exception:
            self._show_error("æ‰“å¼€è§†é¢‘å¤±è´¥", "æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶")

    def _on_camera_open(self):
        """æ‰“å¼€æ‘„åƒå¤´"""
        try:
            self._stop_all()

            camera_id = 0  # é»˜è®¤æ‘„åƒå¤´

            self.current_file = f"æ‘„åƒå¤´ {camera_id}"
            self.current_mode = 'camera'
            self.is_playing = True

            self.left_panel.update_info(f"æ‘„åƒå¤´ {camera_id}", 'camera')

            # å¯åŠ¨æç®€æ’­æ”¾å™¨
            self.video_player.play_camera(camera_id)

            print(f"å¼€å§‹æ‘„åƒå¤´å®æ—¶æ˜¾ç¤º")
                
        except Exception:
            self._show_error("æ‰“å¼€æ‘„åƒå¤´å¤±è´¥", "æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
    
    # ============================================================================
    # æ§åˆ¶æŒ‰é’®å¤„ç†æ–¹æ³•
    # ============================================================================
    
    def _on_start_inference(self):
        """å¼€å§‹æ¨ç†"""
        try:
            # æ£€æŸ¥å¿…è¦æ¡ä»¶
            if not self.current_file:
                QMessageBox.warning(self.ui, "è­¦å‘Š", "è¯·å…ˆé€‰æ‹©åª’ä½“æ–‡ä»¶ï¼")
                return
            
            if not self.model_path or not self.selected_module_type:
                QMessageBox.warning(self.ui, "è­¦å‘Š", "è¯·å…ˆé€‰æ‹©æ¨¡å‹å’Œæ¨¡å—ç±»å‹ï¼")
                return
            
            # åŠ è½½æ¨¡å‹ï¼ˆæ­¤æ—¶æ‰çœŸæ­£åŠ è½½ï¼‰
            if not self._load_yolo_module():
                return
            
            # æ£€æŸ¥å½“å‰æ¨¡å¼
            if self.current_mode == 'image':
                self._process_image()
            elif self.current_mode in ['video', 'camera']:
                self._process_video_camera()
            else:
                QMessageBox.warning(self.ui, "è­¦å‘Š", "è¯·å…ˆé€‰æ‹©åª’ä½“æ–‡ä»¶ï¼")
                
        except Exception as e:
            self._show_error("å¼€å§‹å¤„ç†å¤±è´¥", str(e))
    
    def _process_image(self):
        """å¤„ç†å›¾ç‰‡"""
        try:
            if not self._load_yolo_module():
                return
            
            print(f"å¼€å§‹å¤„ç†å›¾ç‰‡: {self.current_file}")
            
            # åŠ è½½å›¾ç‰‡
            import cv2
            import numpy as np
            from PySide6.QtGui import QImage, QPixmap
            
            image = cv2.imread(self.current_file)
            if image is None:
                QMessageBox.warning(self.ui, "è­¦å‘Š", "æ— æ³•è¯»å–å›¾ç‰‡æ–‡ä»¶")
                return
            
            # è°ƒç”¨YOLOæ¨¡å—å¤„ç†å›¾ç‰‡ï¼ˆè¿”å›å­—å…¸ï¼Œä¸æ˜¯å…ƒç»„ï¼‰
            result_dict = self.current_yolo_module.process_frame(image)
            
            # æå–å¤„ç†åçš„å›¾åƒå’Œç»Ÿè®¡ä¿¡æ¯
            if isinstance(result_dict, dict):
                processed_image = result_dict.get('image', image)
                stats_data = result_dict.get('stats', {})
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å…·ä½“çš„åˆ†ç±»ç»“æœ
                class_name = result_dict.get('class_name', 'æœªçŸ¥')
                confidence = result_dict.get('confidence', 0.0)
                
                # å¦‚æœæœ‰åˆ†ç±»ä¿¡æ¯ï¼Œåœ¨ç»Ÿè®¡ä¿¡æ¯ä¸­æ·»åŠ 
                if class_name != 'æœªçŸ¥':
                    stats_data['detection_count'] = 1 if confidence > 0 else 0
                    stats_data['avg_confidence'] = confidence
                    stats_data['class_name'] = class_name
                    
                    print(f"åˆ†ç±»ç»“æœ: {class_name} ({confidence:.2%})")
            else:
                # å¦‚æœä¸æ˜¯å­—å…¸ï¼Œä½¿ç”¨åŸå§‹å›¾åƒ
                processed_image = image
                stats_data = {}
                print("è­¦å‘Š: YOLOæ¨¡å—è¿”å›çš„ä¸æ˜¯å­—å…¸æ ¼å¼")
            
            # æ˜¾ç¤ºå¤„ç†åçš„å›¾åƒ
            if isinstance(processed_image, np.ndarray):
                # ç¡®ä¿å›¾åƒæ˜¯RGBæ ¼å¼
                if len(processed_image.shape) == 2:  # ç°åº¦å›¾
                    processed_rgb = cv2.cvtColor(processed_image, cv2.COLOR_GRAY2RGB)
                elif processed_image.shape[2] == 4:  # RGBA
                    processed_rgb = cv2.cvtColor(processed_image, cv2.COLOR_BGRA2RGB)
                else:  # BGR
                    processed_rgb = cv2.cvtColor(processed_image, cv2.COLOR_BGR2RGB)
                
                height, width, channel = processed_rgb.shape
                bytes_per_line = 3 * width
                
                q_img = QImage(processed_rgb.data, width, height, 
                              bytes_per_line, QImage.Format_RGB888)
                pixmap = QPixmap.fromImage(q_img)
                self.left_panel.set_display_image(pixmap)
            else:
                print(f"è­¦å‘Š: å¤„ç†åçš„å›¾åƒä¸æ˜¯numpyæ•°ç»„ï¼Œç±»å‹: {type(processed_image)}")
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self.right_panel.update_statistics(
                detection_count=stats_data.get('detection_count', 0),
                confidence=stats_data.get('avg_confidence', 0.0),
                inference_time=stats_data.get('inference_time', 0),
                fps=stats_data.get('fps', 0.0)
            )
            
            # æ˜¾ç¤ºåˆ†ç±»ç»“æœ
            if 'class_name' in stats_data and stats_data['class_name'] != 'æœªçŸ¥':
                self.right_panel.update_detailed_stats(
                    total_processed=1,
                    total_detections=1 if stats_data.get('detection_count', 0) > 0 else 0,
                    avg_inference_time=0,
                    class_distribution=f"{stats_data['class_name']}: {stats_data.get('avg_confidence', 0.0):.2%}"
                )
            
            # æ›´æ–°UIçŠ¶æ€
            self.right_panel.set_control_state(True)
            self.is_processing = True
            
            print(f"å›¾ç‰‡å¤„ç†å®Œæˆ: {self.current_file}")
            
        except Exception as e:
            self._show_error("å›¾ç‰‡å¤„ç†å¤±è´¥", str(e))
    
    def _process_video_camera(self):
        """å¤„ç†è§†é¢‘/æ‘„åƒå¤´"""
        try:
            if not self._load_yolo_module():
                return
            
            # è®¾ç½®YOLOæ¨¡å—åˆ°æŠ“å–å™¨
            self.frame_grabber.set_yolo_module(self.current_yolo_module)
            
            # è·å–æŠ“å–é—´éš”å‚æ•°
            delay_ms = self.right_panel.get_parameters().get('delay_ms', 10)
            grab_interval = max(1, delay_ms // 10)  # æ ¹æ®å»¶è¿Ÿè®¡ç®—é—´éš”
            
            # å¼€å§‹æŠ“å–å¸§
            self.frame_grabber.start_grabbing(grab_interval)
            
            # æ›´æ–°UIçŠ¶æ€
            self.right_panel.set_control_state(True)
            self.is_processing = True
            
            print(f"å¼€å§‹å¤„ç†{self.current_mode}: {self.current_file}")
            print(f"æŠ“å–é—´éš”: æ¯{grab_interval}å¸§æŠ“å–ä¸€æ¬¡")
            
        except Exception as e:
            self._show_error("å¼€å§‹å¤„ç†å¤±è´¥", str(e))
    
    def _on_stop_inference(self):
        """åœæ­¢æ¨ç†"""
        self._stop_processing()
    
    def _on_save_screenshot(self):
        """ä¿å­˜æˆªå›¾"""
        try:
            pixmap = self.left_panel.display_label.pixmap()
            if pixmap and not pixmap.isNull():
                file_filter = "PNGå›¾ç‰‡ (*.png);;JPEGå›¾ç‰‡ (*.jpg *.jpeg);;æ‰€æœ‰æ–‡ä»¶ (*.*)"
                
                if self.current_file:
                    base_name = os.path.splitext(os.path.basename(self.current_file))[0]
                else:
                    base_name = "screenshot"
                
                default_name = f"{base_name}.png"
                
                save_path, _ = QFileDialog.getSaveFileName(
                    self.ui, "ä¿å­˜æˆªå›¾",
                    default_name,
                    file_filter
                )
                
                if save_path:
                    if not save_path.lower().endswith(('.png', '.jpg', '.jpeg')):
                        save_path += '.png'
                    
                    success = pixmap.save(save_path)
                    if success:
                        QMessageBox.information(self.ui, "ä¿å­˜æˆåŠŸ", f"æˆªå›¾å·²ä¿å­˜åˆ°:\n{save_path}")
                        print(f"æˆªå›¾ä¿å­˜åˆ°: {save_path}")
                    else:
                        QMessageBox.warning(self.ui, "ä¿å­˜å¤±è´¥", "æ— æ³•ä¿å­˜æˆªå›¾")
            else:
                QMessageBox.warning(self.ui, "è­¦å‘Š", "æ²¡æœ‰å¯ä¿å­˜çš„å›¾åƒ")
                
        except Exception as e:
            self._show_error("ä¿å­˜æˆªå›¾å¤±è´¥", str(e))
    
    # ============================================================================
    # YOLOæ¨¡å—åŠ è½½æ–¹æ³•
    # ============================================================================
    
    def _load_yolo_module(self) -> bool:
        """åŠ è½½YOLOæ¨¡å—ï¼ˆåœ¨ç‚¹å‡»"å¼€å§‹"æ—¶è°ƒç”¨ï¼‰"""
        try:
            if not self.model_path or not self.selected_module_type:
                QMessageBox.warning(self.ui, "è­¦å‘Š", "è¯·å…ˆé€‰æ‹©æ¨¡å‹å’Œæ¨¡å—ç±»å‹ï¼")
                return False
            
            # æ¨¡å—æ˜ å°„
            module_map = {
                'analyzer': 'yolo_analyzer',
                'classifier': 'yolo_classifier',
                'keypoint': 'yolo_keypoint',
                'Tracker': 'yolo_Tracker',
            }
            
            if self.selected_module_type not in module_map:
                self._show_error("åŠ è½½å¤±è´¥", f"æœªçŸ¥çš„æ¨¡å—ç±»å‹: {self.selected_module_type}")
                return False
            
            module_file = module_map[self.selected_module_type]
            
            # åŠ¨æ€å¯¼å…¥æ¨¡å—
            try:
                yolo_module = importlib.import_module(module_file)
                
                # ç±»åè§„åˆ™: YOLO{æ¨¡å—å}
                class_name = f"YOLO{self.selected_module_type.capitalize()}"
                if hasattr(yolo_module, class_name):
                    yolo_class = getattr(yolo_module, class_name)
                    
                    # è·å–å‚æ•°
                    params = self.right_panel.get_parameters()
                    
                    print(f"æ­£åœ¨æ­£å¼åŠ è½½YOLOæ¨¡å‹: {self.model_path}")
                    print(f"æ¨¡å—ç±»å‹: {self.selected_module_type}")
                    print(f"å‚æ•°: IOU={params['iou_threshold']}, ç½®ä¿¡åº¦={params['confidence_threshold']}")
                    
                    # åˆ›å»ºå®ä¾‹ï¼ˆæ­¤æ—¶æ‰çœŸæ­£åŠ è½½æ¨¡å‹ï¼‰
                    self.current_yolo_module = yolo_class(
                        model_path=self.model_path,
                        iou_threshold=params['iou_threshold'],
                        confidence_threshold=params['confidence_threshold'],
                        device='cpu'  # é»˜è®¤ä½¿ç”¨CPU
                    )
                    
                    self.model_loaded = True
                    
                    # è·å–è¯¦ç»†çš„æ¨¡å‹ä¿¡æ¯
                    model_info = {}
                    if hasattr(self.current_yolo_module, 'model_info'):
                        model_info = self.current_yolo_module.model_info
                    elif hasattr(self.current_yolo_module, 'model'):
                        # å°è¯•ä»YOLOæ¨¡å‹ä¸­æå–ä¿¡æ¯
                        try:
                            from ultralytics import YOLO
                            yolo_model = self.current_yolo_module.model
                            model_info['input_size'] = (640, 640)  # é»˜è®¤
                            model_info['num_classes'] = len(yolo_model.names) if hasattr(yolo_model, 'names') else 'æœªçŸ¥'
                        except:
                            pass
                    
                    # è·å–è¾“å…¥å°ºå¯¸
                    input_size = model_info.get('input_size', 640)
                    if isinstance(input_size, (list, tuple)):
                        input_size_str = f"{input_size[0]}x{input_size[1]}"
                    else:
                        input_size_str = f"{input_size}x{input_size}"
                    
                    # è·å–ç±»åˆ«æ•°é‡
                    class_count = model_info.get('num_classes', 'æœªçŸ¥')
                    
                    # æ›´æ–°UIæ˜¾ç¤ºè¯¦ç»†æ¨¡å‹ä¿¡æ¯
                    module_display_names = {
                        'analyzer': 'ç›®æ ‡æ£€æµ‹',
                        'classifier': 'å›¾åƒåˆ†ç±»',
                        'keypoint': 'å…³é”®ç‚¹æ£€æµ‹',
                        'Tracker': 'ç›®æ ‡è·Ÿè¸ª'
                    }
                    
                    display_name = module_display_names.get(self.selected_module_type, self.selected_module_type)
                    self.right_panel.update_model_info(
                        model_path=self.model_path,
                        task_type=display_name,
                        input_size=input_size_str,
                        class_count=str(class_count)
                    )
                    
                    print(f"âœ… YOLOæ¨¡å—åŠ è½½æˆåŠŸ: {self.selected_module_type}")
                    print(f"   - è¾“å…¥å°ºå¯¸: {input_size_str}")
                    print(f"   - ç±»åˆ«æ•°é‡: {class_count}")
                    return True
                else:
                    raise AttributeError(f"æ¨¡å—ä¸­æ²¡æœ‰æ‰¾åˆ°ç±» {class_name}")
                    
            except ImportError as e:
                self._show_error("å¯¼å…¥å¤±è´¥", f"æ— æ³•å¯¼å…¥æ¨¡å— {module_file}:\n{str(e)}\nè¯·ç¡®ä¿{module_file}.pyæ–‡ä»¶å­˜åœ¨")
                return False
            except Exception as e:
                self._show_error("åŠ è½½YOLOæ¨¡å—å¤±è´¥", str(e))
                self.model_loaded = False
                return False
                
        except Exception as e:
            self._show_error("åŠ è½½YOLOæ¨¡å—å¤±è´¥", str(e))
            self.model_loaded = False
            return False
    
    # ============================================================================
    # è¾…åŠ©æ–¹æ³•
    # ============================================================================
    
    def _stop_all(self):
        """åœæ­¢æ‰€æœ‰å¤„ç†"""
        self._stop_processing()
        self.video_player.stop()
        self.is_playing = False
        self.left_panel.set_controls_enabled(False)
    
    def _stop_processing(self):
        """åœæ­¢å¤„ç†"""
        self.frame_grabber.stop_grabbing()
        self.is_processing = False
        self.right_panel.set_control_state(False)
        print("å¤„ç†å·²åœæ­¢")
    
    def _format_time(self, seconds):
        """æ ¼å¼åŒ–æ—¶é—´ä¸º MM:SS æ ¼å¼"""
        try:
            minutes = int(seconds // 60)
            secs = int(seconds % 60)
            return f"{minutes:02d}:{secs:02d}"
        except:
            return "--:--"
    
    def _show_error(self, title: str, message: str):
        """æ˜¾ç¤ºé”™è¯¯"""
        QMessageBox.critical(
            self.ui, title,
            f"{message}\n\nè¯¦ç»†ä¿¡æ¯è¯·æŸ¥çœ‹æ§åˆ¶å°è¾“å‡ºã€‚"
        )
        print(f"é”™è¯¯ [{title}]: {message}")
        traceback.print_exc()